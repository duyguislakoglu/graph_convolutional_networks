{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::AbstractString)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.\"s\"` instead of `o[\"s\"]`.\n",
      "│   caller = top-level scope at none:0\n",
      "└ @ Core none:0\n",
      "WARNING: redefining constant scipy_sparse_find\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "for p in [\"Knet\", \"Plots\", \"IterTools\", \"PyCall\", \"ArgParse\"]\n",
    "    if !haskey(Pkg.installed(),p)\n",
    "        Pkg.add(p);\n",
    "    end\n",
    "end\n",
    " \n",
    "using Knet\n",
    "using DelimitedFiles\n",
    "using Knet: KnetArray, accuracy, progress, minibatch, cycle, adam, xavier_uniform, progress!\n",
    "using Plots\n",
    "using ArgParse\n",
    "using IterTools: ncycle, takenth, take\n",
    "using Base.Iterators: flatten\n",
    "using LinearAlgebra\n",
    "\n",
    "include(\"utils.jl\")\n",
    "include(\"models.jl\")\n",
    "\n",
    "function train_with_early_stopping(model, data, epochs, lr, window_size)\n",
    "    early_stop_counter = 0\n",
    "    prev_val_loss = 0\n",
    "    iter = 0\n",
    "\n",
    "    trnloss = []\n",
    "    valloss = []\n",
    "    flag = true\n",
    "\n",
    "    function task()\n",
    "\n",
    "        append!(trnloss, model(data))\n",
    "        v_loss = val_loss(model, data)\n",
    "        append!(valloss, v_loss)\n",
    "\n",
    "        if v_loss >= prev_val_loss\n",
    "            early_stop_counter = early_stop_counter + 1\n",
    "        else\n",
    "            early_stop_counter = 0\n",
    "        end\n",
    "        if early_stop_counter == window_size\n",
    "            flag = false\n",
    "        end\n",
    "\n",
    "        iter = iter + 1\n",
    "        prev_val_loss = v_loss\n",
    "\n",
    "        return flag\n",
    "    end\n",
    "\n",
    "    training = adam(model, ncycle(data, epochs), lr=lr)\n",
    "    progress!(flag = task() for x in (x for (i,x) in enumerate(training)) if flag)\n",
    "\n",
    "    return 1:iter, trnloss, valloss\n",
    "end\n",
    "\n",
    "# TODO: take user inputs\n",
    "struct args\n",
    "    epochs\n",
    "    lr\n",
    "    weight_decay\n",
    "    hidden\n",
    "    pdrop\n",
    "    window_size\n",
    "end\n",
    "\n",
    "arguments = args(200, 0.01, 5e-4, 16, 0.5, 10)\n",
    "\n",
    "function val_loss(model,x,y)\n",
    "    output = model(x)[:, idx_val]\n",
    "    nll(output, y[idx_val]) + (arguments.weight_decay * sum(model.layer1.w .* model.layer1.w))\n",
    "end\n",
    "function val_loss(model, d)\n",
    "    mean(val_loss(model,x,y) for (x,y) in d)\n",
    "end\n",
    "\n",
    "function test_loss(model,x,y)\n",
    "    output = model(x)[:, idx_test]\n",
    "    nll(output, y[idx_test]) + (arguments.weight_decay * sum(model.layer1.w .* model.layer1.w))\n",
    "end\n",
    "function test_loss(model,d)\n",
    "    mean(test_loss(model,x,y) for (x,y) in d)\n",
    "end\n",
    "\n",
    "(g::GCN)(x,y) = nll(g(x)[:, idx_train], y[idx_train]) + (arguments.weight_decay * sum(g.layer1.w .* g.layer1.w))\n",
    "(m::MLP)(x,y) = nll(m(x)[:, idx_train], y[idx_train]) + (arguments.weight_decay * sum(m.layer1.w .* m.layer1.w))\n",
    "(m::GCN2)(x,y) = nll(m(x)[:, idx_train], y[idx_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(o::PyObject, s::AbstractString)` is deprecated in favor of dot overloading (`getproperty`) so elements should now be accessed as e.g. `o.\"s\"` instead of `o[\"s\"]`.\n",
      "│   caller = top-level scope at none:0\n",
      "└ @ Core none:0\n",
      "WARNING: redefining constant scipy_sparse_find\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "load_dataset (generic function with 2 methods)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseMatrixCSC{Float32,Int64}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atype = gpu() >= 0 ? KnetArray{Float32,2} : SparseMatrixCSC{Float32,Int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m::GCN2)(x,y) = nll(m(x)[:, idx_train], y[idx_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_dataset(\"cora\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
